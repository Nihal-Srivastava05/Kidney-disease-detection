# Kidney-disease-detection

## Problem Statement

The main task at hand here is to compare the understanding of different models while performing transfer learning. We use the concept of Saliency maps to look at what the model exactly sees while making the prediction. This is then used to see the robustness and generalizability of the models. The domain which we are taking is kidney disease detection (Medical domain) as this is a critial domain where it is vital for results to be correct as small mistake can have huge consiquences.

## Dataset

The dataset which we are using is "CT KIDNEY DATASET: Normal-Cyst-Tumor and Stone" available in Kaggle (https://www.kaggle.com/datasets/nazmul0087/ct-kidney-dataset-normal-cyst-tumor-and-stone). The dataset was gathered from PACS (picture archiving and communication system) systems at various hospitals in Dhaka, Bangladesh, where patients had already been diagnosed with a kidney tumor, cyst, normal, or stone finding. The Coronal and Axial cuts were chosen from both contrast and non-contrast studies, and the protocol for the whole abdomen and urogram was followed. Dataset contains 12,446 unique data within it in which the cyst contains 3,709, normal 5,077, stone 1,377, and tumor 2,283

## Models used
- Inception: In a CNN, an Inception Module is an image model block that attempts to approximate an optimal local sparse structure. Simply put, it allows us to use multiple types of filter sizes in a single image block, rather than being limited to a single filter size, which we then concatenate and pass onto the next layer. The Inception architecture employs parallel 1x1, 3x3, and 5x5 convolutional filters to extract features from the input image at various scales.
- Xception: Xception is a 71-layer deep convolutional neural network. A pretrained version of the network trained on over a million images from the ImageNet database can be loaded. The Xception model learns complex representations of input data using depth wise separable convolutions while reducing computational cost by applying a single filter to each channel of the input feature map.
- ResNet: Residual Network (ResNet) is a deep learning model used in computer vision. It's a Convolutional Neural Network (CNN) architecture with hundreds or thousands of convolutional layers. ResNet's central concept is that it introduced a so-called "identity shortcut connection" that bypasses one or more layers.
- Vision Transformer: Pre-trained Vision Transformer (ViT) model on ImageNet-21k (14 million images, 21,843 classes) at 224x224 resolution. The model is fed images as a series of fixed-size patches (resolution 16x16) that are linearly embedded. A [CLS] token is also added to the beginning of a sequence to be used for classification tasks. Before feeding the sequence to the Transformer encoder layers, absolute position embeddings are also added. Pre-training the model teaches it an inner representation of images, which can then be used to extract features useful for downstream tasks: for example, if you have a dataset of labeled images, you can train a standard classifier by layering a linear layer on top of the pre-trained encoder. 